{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Names: Sam Miller, Sami Hakkareinen\n",
    "Team Name: Iron Hogs\n",
    "CS135 - Project A"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bag-of-Words Representations\n",
    "1A: Design Decision Description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import re\n",
    "\n",
    "\n",
    "# Step 1: Loading the Data\n",
    "# Assuming 'x_train.csv' has a column 'text' for the reviews and 'y_train.csv' has a column 'label'\n",
    "x_train_df = pd.read_csv('/Users/sammiller/Desktop/CS135/projA-release/data_reviews/x_train.csv')\n",
    "y_train_df = pd.read_csv('/Users/sammiller/Desktop/CS135/projA-release/data_reviews/y_train.csv')\n",
    "\n",
    "# Step 2: Cleaning the Data\n",
    "def clean_text(text):\n",
    "    # Remove punctuation and convert to lowercase\n",
    "    text = re.sub(r'[^\\w\\s]', '', text).lower()\n",
    "    return text\n",
    "\n",
    "# Apply cleaning function to the text\n",
    "x_train_df['text'] = x_train_df['text'].apply(clean_text)\n",
    "\n",
    "# Bag-of-Words Vectorization\n",
    "vectorizer = CountVectorizer(stop_words='english')\n",
    "X = vectorizer.fit_transform(x_train_df['text'])\n",
    "y = y_train_df['is_positive_sentiment']\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average ROC AUC: 0.8705677083333334\n",
      "Average ROC AUC: 0.8705677083333334\n",
      "Fitting 5 folds for each of 24 candidates, totalling 120 fits\n",
      "Best ROC AUC:  0.8544079861111111\n",
      "Best Parameters:  {'clf__C': 1, 'clf__max_iter': 100, 'tfidf__max_features': 1000, 'tfidf__ngram_range': (1, 1)}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# Define the Logistic Regression model\n",
    "log_reg = LogisticRegression(random_state=42)\n",
    "\n",
    "# Perform cross-validation and print the average accuracy\n",
    "scores = cross_val_score(log_reg, X, y, cv=5, scoring='roc_auc')\n",
    "print(f\"Average ROC AUC: {scores.mean()}\")\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "log_reg = LogisticRegression(random_state=42)\n",
    "\n",
    "# Perform cross-validation and print the average ROC AUC\n",
    "scores = cross_val_score(log_reg, X, y, cv=5, scoring='roc_auc')\n",
    "print(f\"Average ROC AUC: {scores.mean()}\")\n",
    "\n",
    "# Define a pipeline with TF-IDF Vectorizer and Logistic Regression as the classifier for GridSearch\n",
    "pipeline = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer(stop_words='english')),\n",
    "    ('clf', LogisticRegression(random_state=42)),\n",
    "])\n",
    "\n",
    "# Parameter grid for GridSearch\n",
    "param_grid = {\n",
    "    'tfidf__ngram_range': [(1, 1), (1, 2)],\n",
    "    'tfidf__max_features': [500, 1000],\n",
    "    'clf__C': [0.1, 1, 10],\n",
    "    'clf__max_iter': [100, 200],\n",
    "}\n",
    "\n",
    "# Setup GridSearchCV with the pipeline and parameter grid\n",
    "grid_search = GridSearchCV(pipeline, param_grid, cv=5, scoring='roc_auc', verbose=1)\n",
    "\n",
    "# Fit the model with the originally processed text and labels\n",
    "grid_search.fit(x_train_df['text'], y)\n",
    "\n",
    "# Output the best ROC AUC score and the best parameters\n",
    "print(\"Best ROC AUC: \", grid_search.best_score_)\n",
    "print(\"Best Parameters: \", grid_search.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.13",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c017f1df2ec84156215240b0762243d8e283bbae2bf0907730c1f388e73998cc"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
